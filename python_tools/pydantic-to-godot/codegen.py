import typing
import json
import sys
import os
import inspect
import importlib.util
from pathlib import Path
from pydantic import BaseModel
from pydantic.fields import FieldInfo
import time

# --- é…ç½®å€ (Configuration) ---

# æºæ–‡ä»¶å¤¾ï¼šä½ çš„ Python Schema å­˜æ”¾è™• (æŒ‰ DDD é ˜åŸŸåŠƒåˆ†)
SCHEMA_SOURCE_DIR = Path("./schemas")

# ç›®æ¨™æ–‡ä»¶å¤¾ï¼šGodot è…³æœ¬è¼¸å‡ºçš„æ ¹ç›®éŒ„
GODOT_OUTPUT_DIR = Path("./godot_project/generated")

# --- çµ±è¨ˆé¡ (Statistics) ---
class ConversionStats:
    def __init__(self):
        self.start_time = time.time()
        self.files_scanned = 0
        self.files_success = 0
        self.files_failed = 0
        self.files_skipped = 0 # æ²’æœ‰æ¨¡å‹çš„ç©ºæ–‡ä»¶
        self.models_found = 0
        self.errors: typing.List[str] = []

    def log_error(self, file: Path, msg: str):
        self.files_failed += 1
        self.errors.append(f"[FAIL] {file.name}: {msg}")

    def print_report(self):
        duration = time.time() - self.start_time
        print("\n" + "="*50)
        print(f" ğŸ—ï¸  PYDANTIC TO GODOT CONVERSION REPORT")
        print("="*50)
        print(f" â±ï¸  Duration      : {duration:.2f}s")
        print(f" ğŸ“‚ Files Scanned : {self.files_scanned}")
        print(f" âœ… Files Success : {self.files_success}")
        print(f" âš ï¸  Files Skipped : {self.files_skipped} (No models found)")
        print(f" âŒ Files Failed  : {self.files_failed}")
        print(f" ğŸ“¦ Models Found  : {self.models_found}")
        print("-" * 50)
        
        if self.errors:
            print(" ğŸ›‘ ERROR DETAILS:")
            for err in self.errors:
                print(f"    {err}")
        else:
            print(" ğŸ‰ All systems operational. No errors detected.")
        print("="*50 + "\n")

# --- é¡å‹æ˜ å°„æ ¸å¿ƒ (Type Mapping Core) ---

TYPE_MAP = {
    int: "int",
    float: "float",
    str: "String",
    bool: "bool",
    dict: "Dictionary",
    list: "Array",
}

def get_gd_type(py_type) -> str:
    """å°‡ Python é¡å‹æ˜ å°„ç‚º Godot å¼·é¡å‹"""
    # è™•ç† Optional[T] -> Variant
    if typing.get_origin(py_type) is typing.Union and type(None) in typing.get_args(py_type):
        return "Variant"
        
    origin = typing.get_origin(py_type)
    args = typing.get_args(py_type)

    if origin is list:
        inner_type = get_gd_type(args[0])
        return f"Array[{inner_type}]"
    
    if isinstance(py_type, type) and issubclass(py_type, BaseModel):
        return f"{py_type.__name__}Data"

    return TYPE_MAP.get(py_type, "Variant")

def get_default_value_code(field: FieldInfo) -> str:
    """æå– Pydantic é»˜èªå€¼"""
    if field.is_required():
        return ""
    
    val = field.default
    if val is None: return " = null"
    if isinstance(val, bool): return " = true" if val else " = false"
    if isinstance(val, str): return f' = "{val}"'
    if isinstance(val, (int, float)): return f" = {val}"
    if isinstance(val, list): return " = []"
    if isinstance(val, dict): return " = {}"
    return ""

def generate_class_code(model_cls: typing.Type[BaseModel]) -> str:
    """ç‚ºå–®å€‹ Pydantic æ¨¡å‹ç”Ÿæˆ GDScript é¡ä»£ç¢¼"""
    class_name = f"{model_cls.__name__}Data"
    # å®šç¾©è¡¨åè¦å‰‡ï¼šé¡åå°å¯« + s (ä¾‹å¦‚ Weapon -> weapons)
    # å¦‚æœæœªä¾†éœ€è¦è‡ªå®šç¾©ï¼Œå¯ä»¥è®€å– model_cls.Config
    table_name = model_cls.__name__.lower() + "s"
    fields = model_cls.model_fields
    
    lines = []
    lines.append(f"class_name {class_name}")
    lines.append(f"extends RefCounted") 
    lines.append("")
    
    # [æ–°å¢] ç”Ÿæˆå¸¸é‡ TABLE_NAMEï¼Œæ–¹ä¾¿ä¸Šå±¤ Manager èª¿ç”¨æˆ–çµ±ä¸€ç®¡ç†
    lines.append(f"const TABLE_NAME = \"{table_name}\"")
    lines.append("")

    # 1. è®Šé‡è²æ˜
    for name, field in fields.items():
        gd_type = get_gd_type(field.annotation)
        default_val = get_default_value_code(field)
        lines.append(f"var {name}: {gd_type}{default_val}")
    
    lines.append("")

    # 2. from_dict è§£æå‡½æ•¸ (Deserialize)
    lines.append(f"static func from_dict(data: Dictionary) -> {class_name}:")
    lines.append(f"\tvar instance = {class_name}.new()")
    
    for name, field in fields.items():
        py_type = field.annotation
        origin = typing.get_origin(py_type)
        access_code = f"data['{name}']"
        
        # é‚è¼¯ A: åµŒå¥—åˆ—è¡¨ List[Model]
        if origin is list and isinstance(typing.get_args(py_type)[0], type) and issubclass(typing.get_args(py_type)[0], BaseModel):
            inner_cls = f"{typing.get_args(py_type)[0].__name__}Data"
            lines.append(f"\tif data.has('{name}'):")
            lines.append(f"\t\tvar raw = {access_code}")
            lines.append(f"\t\tif raw is String: raw = JSON.parse_string(raw)")
            lines.append(f"\t\tif raw is Array:")
            lines.append(f"\t\t\tinstance.{name} = []")
            lines.append(f"\t\t\tfor item in raw:")
            lines.append(f"\t\t\t\tinstance.{name}.append({inner_cls}.from_dict(item))")

        # é‚è¼¯ B: åµŒå¥—å–®å€‹å°è±¡ Model
        elif isinstance(py_type, type) and issubclass(py_type, BaseModel):
             inner_cls = f"{py_type.__name__}Data"
             lines.append(f"\tif data.has('{name}'):")
             lines.append(f"\t\tvar raw = {access_code}")
             lines.append(f"\t\tif raw is String: raw = JSON.parse_string(raw)")
             lines.append(f"\t\tinstance.{name} = {inner_cls}.from_dict(raw)")

        # é‚è¼¯ C: åŸºç¤é›†åˆ (List/Dict)
        elif origin in (list, dict):
             lines.append(f"\tif data.has('{name}'):")
             lines.append(f"\t\tvar raw = {access_code}")
             lines.append(f"\t\tif raw is String: instance.{name} = JSON.parse_string(raw)")
             lines.append(f"\t\telse: instance.{name} = raw")

        # é‚è¼¯ D: åŸºç¤é¡å‹
        else:
            lines.append(f"\tif data.has('{name}'): instance.{name} = {access_code}")
            
    lines.append("\treturn instance")
    lines.append("")

    # 3. to_dict åºåˆ—åŒ–å‡½æ•¸ (Serialize)
    lines.append(f"func to_dict() -> Dictionary:")
    lines.append(f"\tvar data = {{}}")
    
    for name, field in fields.items():
        py_type = field.annotation
        origin = typing.get_origin(py_type)
        
        # é‚è¼¯ A: åµŒå¥—åˆ—è¡¨ List[Model]
        if origin is list and isinstance(typing.get_args(py_type)[0], type) and issubclass(typing.get_args(py_type)[0], BaseModel):
             lines.append(f"\tif {name} != null:")
             lines.append(f"\t\tdata['{name}'] = []")
             lines.append(f"\t\tfor item in {name}:")
             lines.append(f"\t\t\tdata['{name}'].append(item.to_dict())")

        # é‚è¼¯ B: åµŒå¥—å–®å€‹å°è±¡ Model
        elif isinstance(py_type, type) and issubclass(py_type, BaseModel):
             lines.append(f"\tif {name} != null:")
             lines.append(f"\t\tdata['{name}'] = {name}.to_dict()")
             
        # é‚è¼¯ C: åŸºç¤é¡å‹
        else:
             lines.append(f"\tdata['{name}'] = {name}")
             
    lines.append(f"\treturn data")
    lines.append("")
    
    # 4. SQLite Helper (å¦‚æœæœ‰ id å­—æ®µ)
    if 'id' in fields:
        # [æ›´æ–°] ä½¿ç”¨ TABLE_NAME å¸¸é‡è€Œä¸æ˜¯ç¡¬ç·¨ç¢¼å­—ç¬¦ä¸²
        lines.append(f"# SQLite Helper")
        lines.append(f"static func get_by_id(db: SQLite, id: String) -> {class_name}:")
        lines.append(f"\tvar result = db.select_rows(TABLE_NAME, \"id = '\" + id + \"'\", [\"*\"])")
        lines.append(f"\tif result.is_empty(): return null")
        lines.append(f"\treturn from_dict(result[0])")

    return "\n".join(lines)

# --- æ–‡ä»¶æƒæèˆ‡è™•ç† (File Scanning & Processing) ---

def load_models_from_file(file_path: Path) -> typing.Tuple[typing.List[typing.Type[BaseModel]], str | None]:
    """
    å‹•æ…‹åŠ è¼‰ Python æ–‡ä»¶ä¸¦æå–å…¶ä¸­å®šç¾©çš„ Pydantic æ¨¡å‹
    è¿”å›: (æ¨¡å‹åˆ—è¡¨, éŒ¯èª¤ä¿¡æ¯)
    """
    module_name = file_path.stem
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    if not spec or not spec.loader:
        return [], "Could not create module spec"
    
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    
    try:
        spec.loader.exec_module(module)
    except Exception as e:
        return [], str(e)
    
    models = []
    for name, obj in inspect.getmembers(module):
        if inspect.isclass(obj) and issubclass(obj, BaseModel) and obj is not BaseModel:
            if obj.__module__ == module_name: 
                models.append(obj)
    
    return models, None

def process_all_schemas():
    """ä¸»æµç¨‹ï¼šéæ­¸æƒæä¸¦ç”Ÿæˆ"""
    stats = ConversionStats()
    
    sys.path.insert(0, str(SCHEMA_SOURCE_DIR.resolve()))
    
    if not SCHEMA_SOURCE_DIR.exists():
        print(f"âŒ Source directory not found: {SCHEMA_SOURCE_DIR}")
        return

    print(f"ğŸ” Scanning {SCHEMA_SOURCE_DIR} for schemas...")
    
    for file_path in SCHEMA_SOURCE_DIR.rglob("*.py"):
        if file_path.name == "__init__.py":
            continue
            
        stats.files_scanned += 1
        relative_path = file_path.relative_to(SCHEMA_SOURCE_DIR)
        
        # æå–æ¨¡å‹
        models, error = load_models_from_file(file_path)
        
        if error:
            stats.log_error(relative_path, error)
            continue
            
        if not models:
            stats.files_skipped += 1
            continue
            
        stats.models_found += len(models)
        
        # ç”Ÿæˆä»£ç¢¼
        try:
            gd_content = ["# GENERATED CODE - DO NOT MODIFY BY HAND", ""]
            for model in models:
                gd_content.append(generate_class_code(model))
                gd_content.append("")
                
            target_path = GODOT_OUTPUT_DIR / relative_path.with_suffix(".gd")
            target_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(target_path, "w", encoding="utf-8") as f:
                f.write("\n".join(gd_content))
            
            stats.files_success += 1
            print(f"  âœ… Generated: {target_path}")
            
        except Exception as e:
            stats.log_error(relative_path, f"Generation failed: {str(e)}")

    # æ‰“å°æœ€çµ‚å ±å‘Š
    stats.print_report()

if __name__ == "__main__":
    process_all_schemas()